# WRO-2025-Oaklabs
Future Engineers 2025 Oaklabs Github Repository

The designed solution of WRO 2025 Future Engineers by our team, Oaklabs, is unique and straightforward. It contains multiple electromechanical components that enhance the autonomous capabilities of our robot. We have used two primary microcontrollers
and divided the tasks of the controllers so that maximum productive output is generated, thereby increasing efficiency in task completion. The two microcontrollers used are an Arduino and a Raspberry Pi 5. The Arduino has a motor driver mounted on top of it, allowing us to interface the DC motor and the Servo motor with ease. Other than the motors, we have connected 2 ultrasonic sensors as well, allowing the robot to maintain a distance between the boundaries of the field. The components used in the Raspberry Pi are an ultrasonic sensor and a camera. The task of the camera is to identify any obstacles in front of the robot, and the ultrasonic sensor is to determine the distance between the obstacle and the robot.

The logic of our robot is an innovative idea as it involves simple variable transmission between the two microcontrollers. We have set 2 main parameters in the Raspberry Pi, which involve getting the distance of the obstacle from the ultrasonic sensor, and color detection and object detection input from the camera. The first parameter of the Raspberry Pi is to determine if the distance between the obstacle and the robot is within 5 cm. If this parameter is satisfied, then we move on to the next parameter, where it should be able to identify if it's a Red or Green block. If the obstacle is within 5cm and if the color of the block is Red then a variable 'R' is sent to the arduino via a data cable informing that the servo motor should turn 50 degrees right, and if the block is green in color then the varible 'L' is sent to the arduino indicating to turnm 50 degrees left. This way we plan on passing the obstacle round.

For the open challenge, since there are no obstacles, the input from the Raspberry Pi's ultrasonic sensor is not needed, but the Orange and Blue lines on the mat are highly useful to us as our turning depends on that. If the Raspberry Pi sees that there is a combination of Blue and then orange lines, then it means that the direction of rotation is clockwise, sending the variable 'C', and if the combination is orange and then blue, then the direction of rotation is counterclockwise, sending the variable 'A'. This way we will turn our robot, ensuring that our car moves efficiently.

In the end, where we have to parallel park, we have decided to first ensure that the robot has completed 3 complete rounds of the mat. We will ensure this by putting an internal counter in the Raspberry Pi to identify how many times the blue and orange lines have been passed. If the robot has identified twelve orange lines and twelve blue lines, then the next time it detects the color pink, it should send the variable 'P' to the Arduino, allowing it to carry out a set of instructions to parallel park. 

This is how we plan on using multiple electromechanical parts to overcome these obstacles and successfully win the competition.
